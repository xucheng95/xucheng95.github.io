<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Xucheng95's Blog</title><meta name="author" content="Xucheng95"><meta name="copyright" content="Xucheng95"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Xucheng95&#39;s Blog">
<meta property="og:url" content="https://xucheng95.github.io/index.html">
<meta property="og:site_name" content="Xucheng95&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://xucheng95.github.io/img/avatar.jpg">
<meta property="article:author" content="Xucheng95">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xucheng95.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://xucheng95.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Xucheng95\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-07-02 11:50:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/homepage.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Xucheng95's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Xucheng95's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/xucheng95" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/07/02/GAIL%E7%AE%97%E6%B3%95/" title="GAIL算法">GAIL算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-07-02T02:37:36.000Z" title="发表于 2025-07-02 10:37:36">2025-07-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">摘要
简述 GAIL 算法的核心思想（结合生成对抗网络与模仿学习）、优势（样本效率高、泛化能力强）及应用场景（机器人控制、自动驾驶等），引出全文框架。
一、引言
1.1 模仿学习背景

传统模仿学习方法（行为克隆、逆强化学习）的局限性
数据分布偏移、样本效率低等问题

1.2 GAIL 算法的提出

解决传统方法痛点的动机
GAIL 在学术界和工业界的影响力

二、GAIL 算法基础
2.1 核心思想

生成器(Generator)与判别器(Discriminator)的对抗博弈
从专家轨迹中学习最优策略的机制

2.2 数学原理

形式化定义：马尔可夫决策过程(MDP)
目标函数：最大化判别器无法区分生成轨迹与专家轨迹的概率
优化算法：策略梯度与价值函数近似

2.3 算法流程


初始化生成器策略和判别器网络
生成器与环境交互产生轨迹
判别器区分生成轨迹与专家轨迹
更新生成器策略以最大化判别器误判率
更新判别器以提高区分能力
迭代至收敛

三、GAIL 与相关算法的对比
3.1 与行为克隆(Behavior Cloning)对比

数据效率对比
对专家数据的依赖程度
泛化能力对比
 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/26/V-trace%E8%AF%A6%E8%A7%A3/" title="V-trace详解">V-trace详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-26T06:34:17.000Z" title="发表于 2024-06-26 14:34:17">2024-06-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">1. 简介
V-trace算法是一种用于深度强化学习的off-policy估值算法，特别适用于分布式环境下的学习。该算法主要应用在DeepMind的IMPALA（Importance Weighted Actor-Learner Architectures）中，用于稳定和高效地训练代理。V-trace通过修正从行为策略生成的样本来估计目标策略的价值函数。

2. 基本概念


Off-Policy：训练时使用的策略（目标策略）与生成样本时的策略（行为策略）不同。为了处理这种差异，需要进行重要性采样。


重要性采样：用于修正行为策略生成的样本，使其能够正确评估目标策略。



3. 算法推导
假设我们有行为策略 μ\muμ 和目标策略 π\piπ。目标是估计目标策略的值函数 VπV^\piVπ。
3.1 重要性采样修正
重要性采样比率定义为：
ρt=π(at∣st)μ(at∣st)\rho_t = \frac{\pi(a_t | s_t)}{\mu(a_t | s_t)} 
ρt​=μ(at​∣st​)π(at​∣st​)​
对于off-policy估值，直接使用重要性采样比率可能会导 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/25/%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0/" title="模仿学习">模仿学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-25T07:34:35.000Z" title="发表于 2024-06-25 15:34:35">2024-06-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">1. 引言
模仿学习是一种通过观察和模仿专家行为来学习策略的机器学习方法。不同于传统的强化学习，模仿学习不依赖于环境的奖励反馈，而是直接从专家的演示中学习。这种方法在自动驾驶、机器人控制、医疗决策等多个领域有着广泛的应用。

2. 模仿学习概述
2.1 模仿学习的定义
模仿学习（Imitation Learning, IL）是一种机器学习方法，通过模仿专家的行为来学习策略。其目标是通过观察和模仿专家的操作，训练一个能够在类似环境中执行相应任务的模型。
2.2 模仿学习的类型
模仿学习主要分为两类：行为克隆（Behavior Cloning, BC）和逆强化学习（Inverse Reinforcement Learning, IRL）。此外，近年来对抗性模仿学习（Adversarial Imitation Learning, AIL）也得到了广泛关注。

3. 行为克隆（Behavior Cloning）
3.1 基本原理
行为克隆是模仿学习中最直接的方法，它将模仿学习问题转化为监督学习问题。通过收集专家的状态-动作对，训练一个模型来拟合这些数据。
3.2 算法流程

收集数据：收集专家 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/25/MAPPO%E8%AF%A6%E8%A7%A3/" title="MAPPO详解">MAPPO详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-25T06:12:27.000Z" title="发表于 2024-06-25 14:12:27">2024-06-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">1. 引言
强化学习（Reinforcement Learning，RL）作为一种通过试错学习来最大化累积奖励的机器学习方法，近年来在解决多代理系统中的协作与竞争问题上取得了显著进展。MAPPO（Multi-Agent Proximal Policy Optimization）算法作为近端策略优化（PPO）的扩展，专门设计用于处理多个智能体在共享环境中的互动，提供了一种有效的解决方案。

2. 强化学习和多代理系统简介
强化学习是通过代理与环境的交互学习最优行动策略的方法，多代理系统则指多个智能体或代理共同存在并作用于同一个环境，其行为互相影响，增加了学习和决策的复杂性。

3. 近端策略优化（PPO）回顾
近端策略优化（PPO）是一种流行的RL算法，通过控制策略更新步长来保证训练的稳定性和效果。其核心在于通过最大化近端策略的改进来更新策略，同时限制更新步长，防止策略跃变。

4. MAPPO算法概述
4.1 MAPPO的基本原理
MAPPO算法结合了PPO的优化框架和多代理系统中的特殊需求，旨在解决多代理系统中的协作和竞争问题。其基本原理包括：


集中训练与分散执行：MAPPO通常 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/25/%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" title="传统的强化学习算法">传统的强化学习算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-25T03:53:35.000Z" title="发表于 2024-06-25 11:53:35">2024-06-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">传统的强化学习算法
在深度强化学习（Deep Reinforcement Learning, DRL）出现之前，传统的强化学习方法已经在理论和应用上取得了许多进展。以下是一些重要的传统强化学习算法，包括其原理、公式推导以及伪代码描述。
1. 动态规划 (Dynamic Programming)
原理
动态规划是一类解决多阶段决策问题的方法，基于贝尔曼方程（Bellman Equation）来求解最优策略和价值函数。其核心思想是通过迭代更新价值函数或 Q 函数，逐步逼近最优解。
公式推导
贝尔曼方程用于描述状态值函数V(s)V(s)V(s)和状态-动作值函数Q(s,a)Q(s, a)Q(s,a)：
V(s)=max⁡a∑s′P(s′∣s,a)[R(s,a,s′)+γV(s′)]V(s) = \max_a \sum_{s&#x27;} P(s&#x27;|s, a) [R(s, a, s&#x27;) + \gamma V(s&#x27;)] 
V(s)=amax​s′∑​P(s′∣s,a)[R(s,a,s′)+γV(s′)]
Q(s,a)=∑s′P(s′∣s,a)[R(s,a,s′)+γ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/25/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BB%B7%E5%80%BC%E4%BC%B0%E8%AE%A1%E4%B8%8E%E4%BC%98%E5%8A%BF%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95/" title="强化学习中的价值估计与优势函数计算方法">强化学习中的价值估计与优势函数计算方法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-25T03:23:58.000Z" title="发表于 2024-06-25 11:23:58">2024-06-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">1. 价值估计方法
1.1 折扣回报 (Discounted Return)
折扣回报方法通过计算从某个状态开始直到回合结束的累计折扣奖励来估计价值函数。其定义为：
Gt=∑k=0∞γkrt+kG_t = \sum_{k=0}^{\infty} \gamma^k r_{t+k} 
Gt​=k=0∑∞​γkrt+k​
其中：

γ\gammaγ 是折扣因子，通常 $0 \leq \gamma \leq 1 $。
$ r_t$ 是时间步 ttt 的即时奖励。

优点

无偏估计：折扣回报利用了整个轨迹的信息，提供了回报的无偏估计。
全局信息：考虑了从当前状态到回合结束的所有奖励，能够反映长期的回报情况。

缺点

高方差：受个别奖励波动的影响较大，容易产生高方差的估计。
延迟反馈：必须等待整个回合结束后才能计算完整的折扣回报，导致反馈延迟，不适用于持续任务或长回合任务。
计算复杂：对于较长的回合，需要储存和处理大量的状态和奖励信息，计算复杂度较高。

1.2 时间差分 (Temporal Difference, TD)
时间差分方法结合了动态规划的思想，通过利用当前奖励和下一状态的估计值来 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/24/PPO%E8%AF%A6%E8%A7%A3/" title="PPO详解">PPO详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-24T09:14:14.000Z" title="发表于 2024-06-24 17:14:14">2024-06-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">1. PPO算法简介
Proximal Policy Optimization (PPO) 是一种广泛使用的强化学习算法，旨在通过限制策略更新的幅度来提高训练的稳定性和效率。PPO结合了策略梯度方法和信赖域策略优化 (Trust Region Policy Optimization, TRPO) 的优势，提出了一种简单但有效的策略更新方法。
PPO的核心思想
PPO通过引入“剪辑”机制来限制策略更新的幅度，从而避免策略在每次更新时发生过大变动。其目标函数为：
LCLIP(θ)=Et[min⁡(rt(θ)A^t,clip(rt(θ),1−ϵ,1+ϵ)A^t)]L^{\text{CLIP}}(\theta) = \mathbb{E}_t \left[ \min \left( r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1 - \epsilon, 1 + \epsilon) \hat{A}_t \right) \right] 
LCLIP(θ)=Et​[min(rt​(θ)A^t​,clip(rt​(θ),1−ϵ,1+ϵ)A^t​)]
其中 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/06/13/docker%E7%9A%84%E4%BD%BF%E7%94%A8/" title="docker的使用">docker的使用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-12T18:42:37.000Z" title="发表于 2024-06-13 02:42:37">2024-06-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Docker/">Docker</a></span></div><div class="content">Docker简介
  Docker是一种开源的容器化平台，旨在自动化应用程序的部署、扩展和管理。Docker将应用程序及其依赖环境打包在一个轻量级、可移植的容器中，确保应用在不同环境中的一致运行。
Docker基本概念


镜像 (Image): Docker镜像是一个只读模板，包含运行应用程序所需的所有文件和配置。镜像可以从Docker Hub等镜像仓库下载，也可以通过Dockerfile自行构建。


容器 (Container): 容器是镜像的一个运行实例，包含应用程序的代码和所有依赖。容器是独立、隔离的环境，可以在任何支持Docker的操作系统上运行。


Dockerfile: Dockerfile是一个文本文件，包含构建Docker镜像所需的所有命令。通过Dockerfile可以自动化构建镜像的过程。


仓库 (Repository): Docker仓库用来存储和分发Docker镜像。Docker Hub是最常用的公共仓库，用户也可以搭建私有仓库。


Docker引擎 (Docker Engine): Docker引擎是Docker的核心组件，负责镜像的构建和容器的运行 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/04/14/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%B1%87%E6%80%BB/" title="深度强化学习汇总">深度强化学习汇总</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-04-14T06:37:10.000Z" title="发表于 2024-04-14 14:37:10">2024-04-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></span></div><div class="content">DQN
  深度Q网络（Deep Q-Network，DQN）是一种结合了深度学习与强化学习的算法，用于解决复杂的决策和控制问题。DQN算法由Google DeepMind团队提出，旨在通过深度神经网络（DNN）来逼近Q值函数，从而实现对高维状态空间的有效处理。
DQN的核心概念

Q学习（Q-Learning）
   Q学习是一种无模型的强化学习算法，通过学习一个动作价值函数（Q函数）来估计在给定状态下执行某个动作的期望回报。Q学习的更新公式为：Q(s,a)←Q(s,a)+α[r+γmax⁡a′Q(s′,a′)−Q(s,a)]Q(s,a) \leftarrow Q(s,a) + \alpha \left[ r + \gamma \max_{a&#x27;} Q(s&#x27;,a&#x27;) - Q(s,a) \right]
Q(s,a)←Q(s,a)+α[r+γa′max​Q(s′,a′)−Q(s,a)]
其中，sss和aaa分别为当前状态和动作，rrr为即时奖励，s′s&#x27;s′为下一状态，γ\gammaγ为折扣因子，α\alphaα为学习率。
深度神经网络（Deep N ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/07/Hexo%E7%9A%84%E4%BD%BF%E7%94%A8/" title="Hexo的使用">Hexo的使用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-06-07T00:52:31.000Z" title="发表于 2023-06-07 08:52:31">2023-06-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Hexo/">Hexo</a></span></div><div class="content">  Hexo是一款基于node.js的博客框架，优势是扩展性强、部署方便、界面美观，本博客网站就是基于此框架搭建而成的。在使用Hexo的过程中，也是遇到了很多问题，本文就这些问题和解决方法进行记录，会持续补充。
  问题1：基于github的Hexo博客搭建流程
  可以参考知乎高赞专栏文章《超详细Hexo+Github博客搭建小白教程》，能解决大部分遇到的问题。
  问题2：代码块的字体大小大于正文
  我用的是butterfly主题，在_config.butterfly.yml中设置code-font-size: 13px，调整代码块字体的大小。多试几次，调整到最终看着比较舒服的大小。
  问题3：公式的字体大小大于正文
  在主题目录下修改mathjax.pug，例如我的路径是/themes/butterfly/layout/includes/third-party/math/mathjax.pug，将其中的scale值由原来的1.2改为1.0就能保证公式和正文对齐。
  问题4：无法部署到github，报出错误“remote: Support for password auth ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Xucheng95</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xucheng95"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xucheng95" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/02/GAIL%E7%AE%97%E6%B3%95/" title="GAIL算法">GAIL算法</a><time datetime="2025-07-02T02:37:36.000Z" title="发表于 2025-07-02 10:37:36">2025-07-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/V-trace%E8%AF%A6%E8%A7%A3/" title="V-trace详解">V-trace详解</a><time datetime="2024-06-26T06:34:17.000Z" title="发表于 2024-06-26 14:34:17">2024-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/25/%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0/" title="模仿学习">模仿学习</a><time datetime="2024-06-25T07:34:35.000Z" title="发表于 2024-06-25 15:34:35">2024-06-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/25/MAPPO%E8%AF%A6%E8%A7%A3/" title="MAPPO详解">MAPPO详解</a><time datetime="2024-06-25T06:12:27.000Z" title="发表于 2024-06-25 14:12:27">2024-06-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/25/%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" title="传统的强化学习算法">传统的强化学习算法</a><time datetime="2024-06-25T03:53:35.000Z" title="发表于 2024-06-25 11:53:35">2024-06-25</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Docker/"><span class="card-category-list-name">Docker</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hexo/"><span class="card-category-list-name">Hexo</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">强化学习</span><span class="card-category-list-count">8</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Docker/" style="font-size: 1.1em; color: #999">Docker</a> <a href="/tags/GAIL/" style="font-size: 1.1em; color: #999">GAIL</a> <a href="/tags/Hexo/" style="font-size: 1.1em; color: #999">Hexo</a> <a href="/tags/PPO/" style="font-size: 1.5em; color: #99a9bf">PPO</a> <a href="/tags/V-trace/" style="font-size: 1.1em; color: #999">V-trace</a> <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">强化学习</a> <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" style="font-size: 1.5em; color: #99a9bf">强化学习基础</a> <a href="/tags/%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0/" style="font-size: 1.5em; color: #99a9bf">模仿学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">深度强化学习</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">七月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">10</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2022-10-28T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-07-02T03:50:50.370Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By Xucheng95</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["你在抱怨什么呢","为明天到来的事，说人生像是没有意义","没有选择会是唯一的路","这不是你自己的问题，人终归要好好去生活"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '你在抱怨什么呢'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>